# Week 2 Progress Tracker

## Day 1: LLM Evaluation Frameworks
- [ ] Read "Evaluating LLMs" paper
- [ ] Read OpenAI evals repo readme
- [ ] Forked evals repo
- [ ] Created custom toxicity refusal eval
- [ ] Generated 50 adversarial prompts
- [ ] Ran evaluation and documented results

## Day 2: Metrics Deep-Dive
- [ ] Implemented exact-match metric
- [ ] Implemented BLEURT
- [ ] Implemented BERTScore
- [ ] Implemented LLM-as-judge
- [ ] Ran all 4 metrics on Week 1 Q&A set
- [ ] Identified discrepancies (>10%)
- [ ] Analyzed when to use which metric

## Day 3: Human-in-the-Loop Label UI
- [ ] Set up Streamlit app
- [ ] Created swipe interface
- [ ] Implemented CSV export
- [ ] Added progress tracking
- [ ] Tested with sample data
- [ ] Deployed or documented local setup

## Day 4: Error Analysis & Prompt Patches
- [ ] Collected 50 failures
- [ ] Categorized into taxonomy:
  - [ ] Ambiguity
  - [ ] Missing context
  - [ ] Format error
  - [ ] Safety refusal
- [ ] Created prompt patch for each class
- [ ] Measured improvement delta
- [ ] Documented results

## Day 5: Case Study Blog Post
- [ ] Selected case study topic
- [ ] Wrote 500+ word post
- [ ] Included metrics (72% â†’ 91%)
- [ ] Added visualizations
- [ ] Published on Medium/LinkedIn
- [ ] Shared on social media

## Week 2 Completion
- [ ] All daily tasks completed
- [ ] All deliverables created
- [ ] Blog post published
- [ ] Ready for Week 3

---

## Notes
_Add your notes, learnings, and observations here_

