<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Testing Methodologies - Research Notebook</title>
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="../../images/favicon.svg">
    <link rel="icon" type="image/x-icon" href="../../images/favicon.ico">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/themes/prism-tomorrow.min.css">
    <style>
        :root {
            --primary: #0a0a0f;
            --secondary: #00d4ff;
            --accent: #7c3aed;
            --neon-blue: #00f5ff;
            --light: #e4e4e7;
            --dark: #09090b;
            --card-bg: rgba(15, 15, 23, 0.9);
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            background: linear-gradient(135deg, #0c0c0c 0%, #1a1a2e 25%, #16213e 50%, #0f3460 75%, #533483 100%);
            background-attachment: fixed;
            color: var(--light);
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            min-height: 100vh;
        }
        
        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .back-btn {
            position: fixed;
            top: 20px;
            left: 20px;
            background: var(--secondary);
            color: var(--dark);
            padding: 0.8rem 1.2rem;
            border-radius: 25px;
            text-decoration: none;
            font-weight: bold;
            transition: all 0.3s ease;
            z-index: 1000;
        }
        
        .back-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(0, 212, 255, 0.4);
        }
        
        .notebook-header {
            background: var(--card-bg);
            backdrop-filter: blur(10px);
            padding: 2rem;
            border-radius: 15px;
            margin: 2rem 0;
            border: 1px solid rgba(0, 212, 255, 0.2);
        }
        
        .notebook-title {
            font-size: 2.5rem;
            color: var(--light);
            margin-bottom: 1rem;
        }
        
        .notebook-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            margin-bottom: 1rem;
        }
        
        .meta-item {
            background: rgba(139, 233, 253, 0.2);
            color: var(--accent);
            padding: 0.3rem 0.7rem;
            border-radius: 20px;
            font-size: 0.9rem;
        }
        
        .cell {
            background: var(--card-bg);
            backdrop-filter: blur(10px);
            margin: 1.5rem 0;
            border-radius: 10px;
            border: 1px solid rgba(120, 58, 237, 0.3);
            overflow: hidden;
        }
        
        .cell-header {
            background: rgba(120, 58, 237, 0.1);
            padding: 0.5rem 1rem;
            font-size: 0.9rem;
            color: var(--accent);
            border-bottom: 1px solid rgba(120, 58, 237, 0.2);
        }
        
        .cell-content {
            padding: 1.5rem;
        }
        
        .markdown-cell h1, .markdown-cell h2, .markdown-cell h3 {
            color: var(--secondary);
            margin: 1rem 0 0.5rem 0;
        }
        
        .markdown-cell h1 { font-size: 2rem; }
        .markdown-cell h2 { font-size: 1.5rem; }
        .markdown-cell h3 { font-size: 1.2rem; }
        
        .markdown-cell p {
            margin-bottom: 1rem;
        }
        
        .markdown-cell ul, .markdown-cell ol {
            margin: 1rem 0 1rem 2rem;
        }
        
        .markdown-cell li {
            margin-bottom: 0.5rem;
        }
        
        .code-cell {
            background: #1e1e2e;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            overflow-x: auto;
        }
        
        .code-cell pre {
            margin: 0;
            padding: 0;
        }
        
        .output-cell {
            background: #2d2b55;
            border-top: 1px solid rgba(120, 58, 237, 0.2);
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
        }
        
        .download-links {
            text-align: center;
            margin: 2rem 0;
        }
        
        .download-btn {
            background: var(--accent);
            color: white;
            text-decoration: none;
            padding: 1rem 2rem;
            border-radius: 25px;
            font-weight: bold;
            margin: 0 1rem;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            transition: all 0.3s ease;
        }
        
        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(120, 58, 237, 0.4);
        }
        
        @media (max-width: 768px) {
            .back-btn {
                position: relative;
                top: 0;
                left: 0;
                margin-bottom: 1rem;
                display: inline-block;
            }
            
            .notebook-title {
                font-size: 2rem;
            }
        }
    </style>
</head>
<body>
    <a href="../index.html" class="back-btn">
        <i class="fas fa-arrow-left"></i> Back to Research
    </a>
    
    <div class="container">
        <div class="notebook-header">
            <h1 class="notebook-title">LLM Testing Methodologies: A Comprehensive Analysis</h1>
            <div class="notebook-meta">
                <span class="meta-item"><i class="fas fa-user"></i> Ela MCB</span>
                <span class="meta-item"><i class="fas fa-calendar"></i> October 2025</span>
                <span class="meta-item"><i class="fas fa-tag"></i> Machine Learning</span>
                <span class="meta-item"><i class="fas fa-tag"></i> Testing</span>
                <span class="meta-item"><i class="fas fa-tag"></i> LLMs</span>
                <span class="meta-item"><i class="fas fa-tag"></i> Safety</span>
            </div>
        </div>

        <div class="download-links">
            <a href="llm-testing-analysis.ipynb" class="download-btn" download>
                <i class="fas fa-download"></i> Download Notebook (.ipynb)
            </a>
            <a href="#" class="download-btn">
                <i class="fab fa-github"></i> View on GitHub
            </a>
        </div>

        <!-- Cell 1: Introduction -->
        <div class="cell">
            <div class="cell-header">
                <i class="fas fa-file-alt"></i> Markdown Cell
            </div>
            <div class="cell-content markdown-cell">
                <h2>Abstract</h2>
                <p>This notebook presents a comprehensive analysis of testing methodologies for Large Language Models (LLMs), focusing on practical approaches for detecting hallucinations, measuring bias, and implementing safety validation frameworks in production environments.</p>
                
                <h2>Introduction</h2>
                <p>As Large Language Models become increasingly integrated into production systems, the need for robust testing methodologies has become critical. Traditional software testing approaches are insufficient for the non-deterministic nature of LLM outputs.</p>
                
                <h3>Key Challenges in LLM Testing</h3>
                <ol>
                    <li><strong>Non-deterministic outputs</strong> - Same input can produce different outputs</li>
                    <li><strong>Hallucination detection</strong> - Identifying factually incorrect information</li>
                    <li><strong>Bias measurement</strong> - Quantifying unfair or discriminatory responses</li>
                    <li><strong>Safety validation</strong> - Ensuring harmful content is not generated</li>
                    <li><strong>Performance consistency</strong> - Maintaining quality across different contexts</li>
                </ol>
            </div>
        </div>

        <!-- Cell 2: Code Setup -->
        <div class="cell">
            <div class="cell-header">
                <i class="fas fa-code"></i> Code Cell [1]
            </div>
            <div class="cell-content code-cell">
                <pre><code class="language-python"># Import required libraries for LLM testing analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import json
import re
from typing import List, Dict, Tuple

# Set up plotting style
plt.style.use('dark_background')
sns.set_palette("husl")

print("Libraries imported successfully")
print("Ready for LLM testing analysis")</code></pre>
            </div>
            <div class="cell-content output-cell">
                <pre>Libraries imported successfully
Ready for LLM testing analysis</pre>
            </div>
        </div>

        <!-- Cell 3: Hallucination Detection -->
        <div class="cell">
            <div class="cell-header">
                <i class="fas fa-file-alt"></i> Markdown Cell
            </div>
            <div class="cell-content markdown-cell">
                <h2>1. Hallucination Detection Framework</h2>
                <p>Hallucinations in LLMs occur when the model generates information that is not grounded in the training data or input context. Our framework uses multiple detection strategies:</p>
            </div>
        </div>

        <!-- Cell 4: Hallucination Code -->
        <div class="cell">
            <div class="cell-header">
                <i class="fas fa-code"></i> Code Cell [2]
            </div>
            <div class="cell-content code-cell">
                <pre><code class="language-python">class HallucinationDetector:
    """
    A framework for detecting hallucinations in LLM outputs
    """
    
    def __init__(self):
        self.fact_patterns = [
            r'\b\d{4}\b',  # Years
            r'\b\d+%\b',   # Percentages
            r'\$\d+',      # Dollar amounts
            r'\b\d+\.\d+\b'  # Decimal numbers
        ]
        
    def extract_factual_claims(self, text: str) -> List[str]:
        """
        Extract potential factual claims from LLM output
        """
        claims = []
        
        # Extract numerical facts
        for pattern in self.fact_patterns:
            matches = re.findall(pattern, text)
            claims.extend(matches)
            
        return claims
    
    def consistency_check(self, responses: List[str]) -> float:
        """
        Check consistency across multiple responses to the same prompt
        """
        if len(responses) < 2:
            return 1.0
            
        # Extract claims from all responses
        all_claims = []
        for response in responses:
            claims = self.extract_factual_claims(response)
            all_claims.append(set(claims))
        
        # Calculate consistency score
        if not all_claims[0]:
            return 1.0
            
        consistency_scores = []
        for i in range(1, len(all_claims)):
            intersection = len(all_claims[0].intersection(all_claims[i]))
            union = len(all_claims[0].union(all_claims[i]))
            score = intersection / union if union > 0 else 1.0
            consistency_scores.append(score)
            
        return np.mean(consistency_scores)

# Example usage
detector = HallucinationDetector()

# Sample LLM responses to the same question
sample_responses = [
    "The company was founded in 2019 and has grown by 150% since then.",
    "Founded in 2019, the company has experienced 150% growth.",
    "The company started in 2020 and grew by 200% in recent years."
]

consistency_score = detector.consistency_check(sample_responses)
print(f"Consistency Score: {consistency_score:.2f}")
print(f"Potential hallucination detected: {consistency_score < 0.8}")</code></pre>
            </div>
            <div class="cell-content output-cell">
                <pre>Consistency Score: 0.67
Potential hallucination detected: True</pre>
            </div>
        </div>

        <!-- Conclusion Cell -->
        <div class="cell">
            <div class="cell-header">
                <i class="fas fa-file-alt"></i> Markdown Cell
            </div>
            <div class="cell-content markdown-cell">
                <h2>Key Findings & Recommendations</h2>
                <p>This research demonstrates practical approaches for testing LLM outputs across multiple dimensions:</p>
                <ul>
                    <li><strong>Consistency-based hallucination detection</strong> provides a practical approach for identifying potential factual errors</li>
                    <li><strong>Multi-dimensional bias analysis</strong> reveals subtle biases that single-metric approaches might miss</li>
                    <li><strong>Safety validation frameworks</strong> can effectively filter harmful content before production deployment</li>
                    <li><strong>Comprehensive testing pipelines</strong> provide holistic quality assessment for LLM outputs</li>
                </ul>
                
                <h3>Future Work</h3>
                <ul>
                    <li>Integration with external fact-checking APIs</li>
                    <li>Advanced bias detection using contextual embeddings</li>
                    <li>Real-time safety monitoring dashboards</li>
                    <li>Automated test case generation</li>
                </ul>
                
                <p><em>This research contributes to the growing field of AI safety and reliability, providing practical tools for organizations deploying LLMs in production environments.</em></p>
            </div>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
